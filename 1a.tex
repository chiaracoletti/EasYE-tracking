
\documentclass[12pt]{article}
\usepackage{geometry} 
\usepackage{setspace}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{indentfirst}

\geometry{a4paper} 


\title{\textbf{EasYE TRACKING}}
\author{Giada Colella \and Chiara Coletti}
\date{15/07/2016} 


\begin{document}
	
\maketitle
\pagebreak

\tableofcontents

\pagebreak

\begin{abstract}
	L' Eye tracking è un complesso processo di misurazione del punto di fissazione oculare. I vantaggi che derivano dall'utilizzo di questa tecnica sono molteplici: a partire da indagini statistiche di mercato fino al miglioramento della comunicazione uomo/macchina.
\end{abstract}
\pagebreak
\section{Introduzione}
Il nostro progetto si pone nella prima fase di realizzazione di un eye tracker. Ha come scopo lo studio del movimento dell'occhio. Partendo da un video, abbiamo cercato di individuare l'occhio e di tracciarne il movimento. Punto focale della nostra ricerca è stato il riconoscimento del centro dell'iride. 

Abbiamo sviluppato il nostro progetto usando {\textbf{"Python"} come linguaggio di programmazione. Per iniziare è necessario aver installato la libreria libera Opencv. Il riconoscimento di volti ed occhi è stato realizzato mediante l'algoritmo "Cascade Classification". Prima di operare, dunque, è stato necessario importare i file classificatori (o "haarcascades") nella cartella di lavoro.
\pagebreak

\section{Dallo Pseudocodice...}
Abbiamo ritenuto utile suddividere il nostro progetto in vari step:
\begin{enumerate}
	\item \label{primo}\textcolor{blue}{Acquisizione video e analisi frame by frame}
	\item \label{secondo} \textcolor{blue}{Conversione dei frame acquisiti in scala di grigi}
	\item \label{terzo} \textcolor{blue}{Riconoscimento del volto}
	\item \label{quarto}\textcolor{blue}{Riconoscimento degli occhi}
    \item \label{quinto}\textcolor{blue}{Riconoscimento cerchi nell'area occhi}
    \item \label{sesto}\textcolor{blue}{Rappresentazione del movimento oculare}
    \item \label{settimo}\textcolor{blue}{Generazione video e chiusura programma}
\end{enumerate}

\pagebreak
\section{...Al codice}


\framebox[15cm]{
	\begin{minipage}[c]{150mm} 
		
		\hspace{4ex}	\%matplotlib inline
		
		\hspace{4ex}	import matplotlib.pyplot as plt\\
			
		\hspace{4ex}	import cv2
		
		\hspace{4ex}	import numpy as np\\
			
		
		\hspace{4ex}	sc\_fct = 1.1       
		    
		\hspace{4ex}	min\_neigh = 5      
		     
		\hspace{4ex}	min\_size\_f = (30,30)  
		   
		\hspace{4ex}	min\_size\_e = (10,10)   
		  
		\hspace{4ex}	mindist\_c=30         
		    
		\hspace{4ex}	dp\_c=1                 
		   
		\hspace{4ex}	param1\_c=60          
		    
		\hspace{4ex}	param2\_c=20          
		   
		\hspace{4ex}	minr\_c=5             
		    
		\hspace{4ex}	maxr\_c=15      \\           
		
			
			
			
		
		\hspace{4ex}	faceCascade =cv2.CascadeClassifier("haarcascade\_frontalface\_default.xml")
		
		\hspace{4ex}	eyeCascade=cv2.CascadeClassifier("haarcascade\_eye.xml")\\
		
		
	\end{minipage}}
	\\
	\\
	\\
	\\
	Importiamo le librerie oportune, introduciamo i parametri che ci torneranno utili nella stesura del codice ed importiamo le Haarcascades che userem per il riconoscimento di volto e occhi.
\pagebreak




\ref {primo} \underline{\textcolor{blue}{Acquisizione video e analisi frame by frame}}
    \\
    \\
    \\
    \\
    \framebox[16cm]{
  	 \begin{minipage}[c]{150mm} 
  		\begin{center}
  			video\_capture=cv2.VideoCapture(0) \\
  			cv2.namedWindow("Face and eyes")\\
  			ret, frame = video\_capture.read()\\
  		\end{center}
	\end{minipage}}
	\\
	\\
	\\
	\\
	Abbiamo importato il video dalla webcam, rinominato la finestra video e salvato in "frame" gli elementi su cui poi andremo a lavorare. L'ultima operazione vine inserita all'interno di un ciclo while che verrà interrotto solo al termine dell'esecuzione dell'intero programma.
	\\
	\\
	\\
	\\
	\framebox[16cm]{
	\begin{minipage}[c]{150mm} 
		\begin{center}
			x\_dim=video\_capture.get(3)\\
			y\_dim=video\_capture.get(4)
		\end{center}
	\end{minipage}}
	\\
	\\
	\\
	\\
	Definisco x\_dim e y\_dim come le dimensioni del video in entrata. Saranno utili in seguito.
\pagebreak
  
  
\ref {secondo} \underline{\textcolor{blue}{Conversione dei frame acquisiti in scala di grigi}}
   \\
   \\
   \\
  
   \framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  			gray = cv2.cvtColor(frame, cv2.COLOR\_BGR2GRAY)
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Applichiamo la funzione 'cvtColor' specificando il tipo di conversione da eseguire (in questo caso convertiamo da una figura a colori ad una a scala di grigi mediante il comando cv2.COLOR\_BGR2GRAY). La funzione viene applicata a 'frame' ovvero la zona di memoria in cui vengono salvati i singoli frame del video.
\pagebreak
  	
  	
  
\ref {terzo} \underline{\textcolor{blue}{Riconoscimento del volto}}
    \\
    \\
    \\
  
    \framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  		    faces = faceCascade.detectMultiScale(  \\     
  		    gray,\\
  		    scaleFactor=sc\_fct,\\
  		    minNeighbors=min\_neigh,\\
  	    	minSize=min\_size\_f	)\\	
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Applichiamo la funzione 'detectMultiscale' e utilizziamo le cascaspecificando il tipo di conversione da eseguire (in questo caso convertiamo da una figura a colori ad una a scala di grigi mediante il comando cv2.COLOR\_BGR2GRAY). La funzione viene applicata a 'gray' ovvero la zona di memoria in cui abbiamo salvato i risultati della conversione dei vari frame in scala di grigi. Salviamo l'output della funzione (una lista di quattro elementi: coordinata x e coordinata y del vertice superiore sinistro del rettangolo, base e altezza) in "faces".
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  			for (x, y, w, h) in faces:\\
  			cv2.rectangle(frame,(x, y), (x+w, y+h), (0, 255, 0), 2)\\
  	    \end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Tracciamo i rettangoli attorno ai volti riconosciuti mediante la funzione 'rectangle'.
\pagebreak
  	
  	
\ref {quarto} \underline{\textcolor{blue}{Riconoscimento degli occhi}}
  	\\
  	\\
  	\\
  	\\ 
    \framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
    	 \begin{center}
  	     roi\_gray=gray[y:y+h/2,x:x+w] \\
  	     roi\_color=frame[y:y+h/2,x:x+w]	\\
  	  \end{center}
    \end{minipage}}
    \\
    \\
    \\
    \\
   Definisco nuove aree di lavoro: rappresentano la stessa area (limitata alla metà superiore del volto), la prima è in scala di grigi, la seconda a colori.
    \\
    \\
    \\
    \\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  	 		eyes= eyeCascade.detectMultiScale(      \\ 	
  	 		roi\_gray,\\
  	 		scaleFactor=sc\_fct,\\
  	 		minNeighbors=min\_neigh,\\
  	 		minSize=min\_size\_e ) \\ 	 			 			
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Applichiamo nuovamente la funzione 'detectMultiscale'. Questa volta la funzione viene applicata a 'roi\_gray'.Salviamo l'output della funzione in "eyes".
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  	 		for (ex, ey, ew, eh) in eyes:\\
  	 		cv2.rectangle(roi\_color, (ex, ey), (ex+ew, ey+eh), (255, 191, 0, 2)
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Tracciamo i rettangoli attorno agli occhi riconosciuti mediante la funzione 'rectangle'.
 \pagebreak
  	 	
 \ref {quinto} \underline{\textcolor{blue}{Riconoscimento cerchi nell'area occhi}}
  	\\
  	\\
  	\\
  	\\
  	 	
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  			roi\_gray2=roi\_gray[ey:ey+eh,ex:ex+ew]\\
  			roi\_color2=roi\_color[ey:ey+eh,ex:ex+ew]
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	Definisco nuove aree di lavoro: rappresentano la stessa area (limitata ai rettangoli degli occhi riconosciuti), la prima è in scala di grigi, la seconda a colori.
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}				
  	        circles = cv2.HoughCircles(roi\_gray2,cv2.HOUGH\_GRADIENT,dp=dp\_c,minDist=mindist\_c,
  			param1=param1\_c,param2=param2\_c,minRadius=minr\_c,maxRadius=maxr\_c)
  	   	\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	 Applichiamo la funzione 'HoughCircles' per il riconoscimento degli occhi nell'area inserita come input (roi\_gray2). Salviamo l'output della funzione (una lista di tre elementi: coordinata x, coordinata  e raggio del cerchio riconosciuto) in "circles".
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  			if(circles==None):\\
  			continue\\
  			else:\\
  			circles = np.uint16(np.around(circles[0,:]))\\	
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
  	\\
  	 Introduciamo la condizione che ci permette di "bypassare" i frame in cui non viene riconosciuto alcun cerchio. Nel caso in cui, invece, il cerchio venga riconosciuto, 'circles' viene trasformato in un ato di tipo intero.
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  			 for (x\_c,y\_c,r) in circles:
  			 cv2.circle(roi\_color2,(x\_c,y\_c),r,(0,255,0),2)
  			 cv2.circle(roi\_color2,(x\_c,y\_c),2,(0,0,255),3)
  		\end{center}
  	\end{minipage}}
  	\\
    \\
	\\
	\\
	Tracciamo i cerchi e il loro centro.
\pagebreak
  	 				
  	 				
  	 				
  	 				
\ref {sesto} \underline{\textcolor{blue}{Rappresentazione del movimento oculare}}
  	\\
  	\\
  	\\
  	\\
  	\framebox[16cm]{
  	\begin{minipage}[c]{150mm} 
  		\begin{center}
  				plt.scatter(x+ex+x\_c,y+ey+y\_c, s=100, c='r',alpha=0.3)\\
  				plt.axis([0,x\_dim,0,y\_dim])\\
  				plt.draw()\\
  		\end{center}
  	\end{minipage}}
  	\\
  	\\
  	\\
    \\
  	Introduco uno scatterplot di dimensioni (x\_dim e y\_dim) pari alle dimensioni del video in cui visualizzo il centro di cerchio trovato. I punti hanno una trasparenza tale da permettere di osservare le zone dello scatterplot più dense di punti: ovvero quelle zone in cui lo il centro dell'iride è stato più presente.
\pagebreak


\ref {settimo} \underline{\textcolor{blue}{Generazione video e chiusura programma}}
   \\
   \\
   \\
   \\
   \framebox[16cm]{
	\begin{minipage}[c]{150mm} 
		\begin{center}
		cv2.imshow('Face and eyes', frame)
		\end{center}
	\end{minipage}}
	\\
	\\
	\\
	\\
   Mostriamo il video. In 'frame' saranno state apportate le modifiche delle varie aree di interesse. Nel video saranno dinque mostrati i rettangoli dei volti e degli occhi riconosciuti e i cerchi trovati all'interno dei rettangoli degli occhi.
   \\
   \\
   \\
   \\
   \framebox[16cm]{
   \begin{minipage}[c]{150mm} 
   \begin{center}
   if cv2.waitKey(1)==27:\\
   break
   \end{center}
   \end{minipage}}
   \\
   \\
   \\
   \\
   Interuzione del ciclo iniziato al momento della cattura dei frame e chiusura della finestra video quando viene premuto il tasto 'Esc'.
   \\
   \\
   \\
   \\
   \framebox[16cm]{
   \begin{minipage}[c]{150mm} 
   \begin{center}
   video\_capture.release()\\
   cv2.destroyAllWindows()
   \end{center}
   \end{minipage}}
   \\
   \\
   \\
   \\
   Chiusura di tutte le finestre.
   
\pagebreak  	 					
 
\section{Codice completo}

  \%matplotlib inline \\
  import matplotlib.pyplot as plt\\

  import cv2\\
  import numpy as np\\


  sc\_fct = 1.1             \\
  min\_neigh = 5    \\          
  min\_size\_f = (30,30)      \\
  min\_size\_e = (10,10)     \\ 
  mindist\_c=30     \\         
  dp\_c=1          \\         
  param1\_c=60      \\       
  param2\_c=20       \\      
  minr\_c=5          \\     
  maxr\_c=15        \\      


  faceCascade = cv2.CascadeClassifier("haarcascade\_frontalface\_default.xml")\\
  eyeCascade=cv2.CascadeClassifier("haarcascade\_eye.xml")\\


  video\_capture = cv2.VideoCapture(0)\\
  cv2.namedWindow("Face and eyes")\\

  x\_dim=video\_capture.get(3)\\
  y\_dim=video\_capture.get(4)\\

  while True:\\
    ret, frame = video\_capture.read()\\


  gray = cv2.cvtColor(frame, cv2.COLOR\_BGR2GRAY)\\


  faces = faceCascade.detectMultiScale(       \\
  gray,\\
  scaleFactor=sc\_fct,\\
  minNeighbors=min\_neigh,\\
  minSize=min\_size\_f)\\

  for (x, y, w, h) in faces:\\
  cv2.rectangle(frame,(x, y), (x+w, y+h), (0, 255, 0), 2)\\


roi\_gray=gray[y:y+h/2,x:x+w]\\
roi\_color=frame[y:y+h/2,x:x+w]\\

eyes= eyeCascade.detectMultiScale(       \\  
roi\_gray,\\
scaleFactor=sc\_fct,\\
minNeighbors=min\_neigh,\\
minSize=min\_size\_e)\\
  	 				
for (ex, ey, ew, eh) in eyes:\\
cv2.rectangle(roi\_color, (ex, ey), (ex+ew, ey+eh), (255, 191, 0), 2)\\
  	 				
  	 				
roi\_gray2=roi\_gray[ey:ey+eh,ex:ex+ew]\\
roi\_color2=roi\_color[ey:ey+eh,ex:ex+ew]\\
		
circles cv2.HoughCircles(roi\_gray2,cv2.HOUGH\_GRADIENT,dp=dp\_c,\\minDist=mindist\_c,
param1=param1\_c,param2=param2\_c,minRadius=minr\_c,\\maxRadius=maxr\_c)\\
 				
if(circles==None):\\
continue\\
else:\\
  	 				
circles = np.uint16(np.around(circles[0,:]))\\

for (x\_c,y\_c,r) in circles:\\
cv2.circle(roi\_color2,(x\_c,y\_c),r,(0,255,0),2)\\
cv2.circle(roi\_color2,(x\_c,y\_c),2,(0,0,255),3)\\
  	 				
plt.scatter(x+ex+x\_c,y+ey+y\_c, s=100, c='r',alpha=0.3)\\
plt.axis([0,x\_dim,0,y\_dim])\\
plt.draw()\\

cv2.imshow('Face and eyes', frame)\\
if cv2.waitKey(1)==27:\\
break\\

video\_capture.release()\\
cv2.destroyAllWindows()\\


\pagebreak
\section{Conclusioni}



\end{document}